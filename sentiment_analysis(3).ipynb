{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Positive, Negative 말고 Neutral 데이터도 추가해서 ML모델을 만들고 성능을 분석하기 (Pos, Neg만 썼을 때와 성능 차이 있나?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Positive', 'Negative', 'Neutral'}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_training = pd.read_csv('twitter_training.csv')\n",
    "df_new_t = df_training[~df_training.iloc[:,2].isin(['Irrelevant'])]\n",
    "\n",
    "categories_t = df_new_t.iloc[:, 2].tolist()\n",
    "reviews_t = df_new_t.iloc[:, 3].tolist()\n",
    "reviews_t = [str(doc) if pd.notna(doc) else '' for doc in reviews_t]\n",
    "\n",
    "print(set(categories_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "english_stops = set(stopwords.words('english'))\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "#리뷰 전처리\n",
    "def preprocess_reviews(reviews):\n",
    "    processed_reviews = []\n",
    "    for review in reviews:\n",
    "        if isinstance(review, str):  # 리뷰가 문자열인지 \n",
    "            tokens = tokenizer.tokenize(review.lower())\n",
    "            filtered_words = [word for word in tokens if word not in english_stops]\n",
    "            processed_reviews.append(' '.join(filtered_words))\n",
    "        else:\n",
    "            processed_reviews.append('') \n",
    "    return processed_reviews\n",
    "\n",
    "# 리뷰 전처리 실행\n",
    "cleaned_reviews_t = preprocess_reviews(reviews_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Positive', 'Negative', 'Neutral'}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_validation = pd.read_csv('twitter_validation.csv')\n",
    "df_new_v = df_validation[~df_validation.iloc[:,2].isin(['Irrelevant'])]\n",
    "\n",
    "categories_v = df_new_v.iloc[:, 2].tolist()\n",
    "reviews_v = df_new_v.iloc[:, 3].tolist()\n",
    "reviews_v = [str(doc) if pd.notna(doc) else '' for doc in reviews_v]\n",
    "print(set(categories_v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_reviews_v = preprocess_reviews(reviews_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.7428149973253797\n",
      "Validation Accuracy: 0.7596618357487923\n",
      "Training F1 Score: 0.7385551269988125\n",
      "Validation F1 Score: 0.7568696623589081\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# TF-IDF 벡터화\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000) \n",
    "train_features = tfidf_vectorizer.fit_transform(reviews_t)\n",
    "test_features = tfidf_vectorizer.transform(reviews_v)\n",
    "\n",
    "model = MultinomialNB()  \n",
    "model.fit(train_features, categories_t)\n",
    "\n",
    "# 예측\n",
    "train_pred = model.predict(train_features)\n",
    "val_pred = model.predict(test_features)\n",
    "\n",
    "# 성능 평가\n",
    "train_accuracy = accuracy_score(categories_t, train_pred)\n",
    "val_accuracy = accuracy_score(categories_v, val_pred)\n",
    "train_f1 = f1_score(categories_t, train_pred, average='weighted')\n",
    "val_f1 = f1_score(categories_v, val_pred, average='weighted')\n",
    "\n",
    "\n",
    "print(f\"Training Accuracy: {train_accuracy}\")\n",
    "print(f\"Validation Accuracy: {val_accuracy}\")\n",
    "print(f\"Training F1 Score: {train_f1}\")\n",
    "print(f\"Validation F1 Score: {val_f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**결과**\n",
    "\n",
    "앞에서 이진 분류(Positive/Negative)에서 성능이 다음과 같았다.\n",
    "\n",
    "Training Accuracy: 0.8681\n",
    "Validation Accuracy: 0.8932, \n",
    "Training F1 Score: 0.8679\n",
    "Validation F1 Score: 0.8932\n",
    "\n",
    "다중 분류(Positive/Negative/Neutral)에서 성능이 다음과 같았다.\n",
    "\n",
    "Training Accuracy: 0.7428\n",
    "Validation Accuracy: 0.7597\n",
    "Training F1 Score: 0.7386\n",
    "Validation F1 Score: 0.7569\n",
    "\n",
    "그 결과 다중 분류에서 성능이 저하된 걸 볼 수 있다. \n",
    "\n",
    "이진 분류에서는 두 감성 클래스 간의 차이가 명확하고 구분이 쉬운 반면, 다중 분류에 중립 클래스가 추가되면서 각 감성 간의 구분이 복잡해진 것 같다. \n",
    "\n",
    "또한 Naive Bayes는 각 특징이 독립적이라는 가정을 바탕으로 동작한다. 감성 분석에서 중립 클래스는 긍정 및 부정 감성이 혼합된 특징을 가져서 독립성 가정이 성능에 부정적 영향을 미친 것으로 보인다.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nltk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
